<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>WeiWeiWesley</title>
    <link>/</link>
    <description>Recent content on WeiWeiWesley</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 08 Oct 2020 09:47:51 +0800</lastBuildDate><atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Day30 系列文總結與回顧</title>
      <link>/posts/2020-ithome-day30/</link>
      <pubDate>Thu, 08 Oct 2020 09:47:51 +0800</pubDate>
      
      <guid>/posts/2020-ithome-day30/</guid>
      <description>&lt;p&gt;這次很快的來到了鐵人賽最後一天呢～今天讓我們簡單的回顧一下，系列文的結構與其中可能值得運用的地方。&lt;a href=&#34;https://ithelp.ithome.com.tw/users/20103420/ironman/3134&#34;&gt;Go Distributed &amp;amp; Go Consistently&lt;/a&gt; 這系列文以 golang 為基底，目標在建立可靠的分散式服務或系統，如果是直接跳到本篇總結的朋友，不訪參考一下結構分析，再決定本系列文是否有適合你的地方。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Day29 Drone (Install &amp; Usage)</title>
      <link>/posts/2020-ithome-day29/</link>
      <pubDate>Wed, 07 Oct 2020 09:11:26 +0800</pubDate>
      
      <guid>/posts/2020-ithome-day29/</guid>
      <description>&lt;p&gt;本系列文已經接近尾深，今天分享一個跟前面比較不一樣的主題，Drone CI/CD。分享這個工具的主因，是因為體會過 CI/CD 的美好就回不去了，剛好 Drone 是一套以 golang 編程的 CI/CD 工具，本篇讓我們使用 Github repo 當作目標，實現簡易的 CI testting。
&lt;a href=&#34;https://drone.io/&#34;&gt;&lt;img src=&#34;https://i.imgur.com/nv3AUgI.png&#34; alt=&#34;drone&#34;&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Day27 NSQ (Client Usage &amp; RDY)</title>
      <link>/posts/2020-ithome-day27/</link>
      <pubDate>Mon, 05 Oct 2020 14:45:17 +0800</pubDate>
      
      <guid>/posts/2020-ithome-day27/</guid>
      <description>&lt;p&gt;昨天簡單介紹過 NSQ架構與組成要件，今天我們來看一下實際使用的方式，與使用時需要注意的地方。範例會延續昨天架在 kubernetes 的 NSQ，請還沒有安裝朋友，自行利用&lt;a href=&#34;https://github.com/WeiWeiWesley/ithome12/tree/master/kubernetes/nsqExample&#34;&gt;範例設定&lt;/a&gt;部署。&lt;/p&gt;
&lt;p&gt;如果照著範例啟動的話，我們可以得到 3個使用相同 channel 的 consumer pods，與一個負責推送訊息至 topic 的 producer。注意到這次範例實作 Producer-Consumer Mode，故 3個 consumer 收到的 messages 總數，應等於 channel messages 總數。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/9OUPKD4.png&#34; alt=&#34;nsqadmin&#34;&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Day28 NSQ (Tips)</title>
      <link>/posts/2020-ithome-day28/</link>
      <pubDate>Mon, 05 Oct 2020 14:45:17 +0800</pubDate>
      
      <guid>/posts/2020-ithome-day28/</guid>
      <description>&lt;p&gt;針對一些可能遇到的問題或需求，跟大家分享一下須注意的地方或處裡的方式。&lt;/p&gt;
&lt;h2 id=&#34;config-options&#34;&gt;Config Options&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;MaxAttempts : NSQ consumer 嘗試處理訊息次數，並非無限的，預設 5次，可透過 max_attempts 進行變更&lt;/li&gt;
&lt;li&gt;BackoffStrategy : 每次重新嘗試處理訊息時，會對 &lt;code&gt;backoff +1&lt;/code&gt; ，表示下一次重新處理的時間將延後，預設延遲為指數性成長(ex 2, 4, 16 &amp;hellip;)&lt;/li&gt;
&lt;li&gt;MsgTimeout : 可設置訊息若堆積過久，沒有被送到 client 端時，自動失效&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Day26 NSQ (Features &amp; Install)</title>
      <link>/posts/2020-ithome-day26/</link>
      <pubDate>Sun, 04 Oct 2020 15:12:12 +0800</pubDate>
      
      <guid>/posts/2020-ithome-day26/</guid>
      <description>&lt;p&gt;在進行分散式運算時如果是想發送至不同實體， 我們可直接發出請求並等待回傳結果，但這樣在等待回傳時的運算能力是被閒置的，故此聰明的我們可能會用 &lt;code&gt;goroutine&lt;/code&gt; 將請求發送去，再利用 &lt;code&gt;select channel&lt;/code&gt; 等待回傳結果。但大量使用 &lt;code&gt;channel&lt;/code&gt; 的設計又較為複雜，維護較為困難，且依然有著請求對象沒有收到請求，或收到請求沒有回傳這樣不好處理的狀況。&lt;/p&gt;
&lt;p&gt;為了處理上述一些在訊息傳遞交換過程所面臨的問題，我們除了在邏輯上，對服務進行切分成更小的服務顆粒，對於傳遞過程可能造成的錯誤與重試必須進行掌控。NSQ 實作了我們對于訊息交換的需求，特別是在自動重試這個部分，NSQ 幫助我們可以確保資訊是有被接受並處理的。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Day25 Istio (Load Balance gRPC)</title>
      <link>/posts/2020-ithome-day25/</link>
      <pubDate>Sat, 03 Oct 2020 11:31:26 +0800</pubDate>
      
      <guid>/posts/2020-ithome-day25/</guid>
      <description>&lt;p&gt;今天我們實作 gRPC services，觀察 gRPC services 是否可以在有 Istio 的協助下，真的能夠順利的對流量進行 load balance。&lt;/p&gt;
&lt;h2 id=&#34;test-example&#34;&gt;Test Example&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/WeiWeiWesley/ithome12/tree/master/kubernetes/gRPCExample&#34;&gt;下載完整範例&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/WeiWeiWesley/ithome12/blob/master/kubernetes/gRPCExample/client/grpc-client.yaml&#34;&gt;gRPC client * 1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/WeiWeiWesley/ithome12/blob/master/kubernetes/gRPCExample/server/grpc-server.yaml&#34;&gt;gRPC server * 3&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/WeiWeiWesley/ithome12/blob/master/kubernetes/gRPCExample/server/main.go&#34;&gt;Server side&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Day24 Istio (Install &amp; Simple Usage)</title>
      <link>/posts/2020-ithome-day24/</link>
      <pubDate>Fri, 02 Oct 2020 10:35:18 +0800</pubDate>
      
      <guid>/posts/2020-ithome-day24/</guid>
      <description>&lt;p&gt;我們今天飛遠一點，來介紹一下 Istio。Istio 可以提供我們更好的 load balance 能力，特別是在使用 gRPC 連線時，當前版本的 Kubernetes 本身是無法對 gRPC 連線進行 load balance 的，我們需要自己實作 sidecar 來完成 load balance 的目的，而 Istio 正好提供了我們所需要的功能。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Day23 Kubernetes (Kubernetes on Docker Desktop &amp; Pod Lifetime)</title>
      <link>/posts/2020-ithome-day23/</link>
      <pubDate>Thu, 01 Oct 2020 15:04:13 +0800</pubDate>
      
      <guid>/posts/2020-ithome-day23/</guid>
      <description>&lt;p&gt;今天會用一個簡單範例跟大家分享 Pods 的生命週期，藉由範例觀察 Pods status 的變化。但在此之前先，另外介紹一個在本機啟用 Kubernetes 的方式，如果有安裝 Docker Desktop 的話，可以透過介面的方式，產出本地運行的 Kubernetes cluster，與 MineKube 不同的是它提供 GUI，這在我們觀察狀態進行監控的時候會更加友善。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Day22 Kubernetes (Minikube &amp; Deployment)</title>
      <link>/posts/2020-ithome-day22/</link>
      <pubDate>Wed, 30 Sep 2020 08:58:34 +0800</pubDate>
      
      <guid>/posts/2020-ithome-day22/</guid>
      <description>&lt;p&gt;今天我們會先介紹部署檔的構成，再利用 Minikube 在本機建立測試環境，實際感受一下 Pod 如何被創建與異動的。&lt;/p&gt;
&lt;h2 id=&#34;controllers&#34;&gt;Controllers&lt;/h2&gt;
&lt;p&gt;描述檔是用來描述或更新 Pods 的設定，當我們寫好 .yaml 並且利用命令或介面部署上 kubernetes，等同於實作了一個 &lt;a href=&#34;https://kubernetes.io/docs/concepts/overview/working-with-objects/kubernetes-objects/&#34;&gt;Kubernetes objects&lt;/a&gt;，藉此創建 &lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/#when-to-use-a-replicaset&#34;&gt;ReplicaSet&lt;/a&gt;(一群同性質的 Pods) 或更新其狀態。特別提一下會用 Controllers 當標題，是因為&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/&#34;&gt;官方文件&lt;/a&gt;的分類，將各種描述設定所啟用後的 replica，分別歸類在此類別下，筆者自己覺得滿特別的。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Day21 Kubernetes (Pods &amp; Services)</title>
      <link>/posts/2020-ithome-day21/</link>
      <pubDate>Tue, 29 Sep 2020 10:03:28 +0800</pubDate>
      
      <guid>/posts/2020-ithome-day21/</guid>
      <description>&lt;p&gt;昨天我們認識了 kubernetes 基礎架構，由 Cluster, Master Node, Worker Nodes 構成。今天我們要來了解一下 Node 裏實際最小工作單位 Pod，以及用來訪問隨著 Master 調度可能改變 ip address 的 Service。&lt;/p&gt;
&lt;h2 id=&#34;pod&#34;&gt;Pod&lt;/h2&gt;
&lt;p&gt;Pod 是 Kubernetes 下最小工作單位，分布在不同的 Nodes 中，由 Master 管理與調度。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每一 Pod 都為獨立實體，有獨立的虛擬 ip address、獨站部分實體資源&lt;/li&gt;
&lt;li&gt;每一個 Pod 裡面可以運行多個 containers，裡面的 containers 共享該 Pod 的資源&lt;/li&gt;
&lt;li&gt;Pod 內 containers 共享同一個 pod ip address&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Day20 Kubernetes (Cluster Architecture)</title>
      <link>/posts/2020-ithome-day20/</link>
      <pubDate>Mon, 28 Sep 2020 09:56:21 +0800</pubDate>
      
      <guid>/posts/2020-ithome-day20/</guid>
      <description>&lt;p&gt;今天介紹一下以 golang 為主編程語言，建立當前最知名的容器管理服務 — Kubernetes。我們在上一篇已經簡單的敘述過，服務是如何演進成分散式服務，而微服務又是如何因應分散式服務而產生，今天的我們會介紹 Kubernetes 的運作架構，以及關於 Kubernetes 幾個關鍵名詞解釋，Here we go。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/BJOsuWS.png&#34; alt=&#34;k8s-golang&#34;&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Day19 Distributed Micoservices</title>
      <link>/posts/2020-ithome-day19/</link>
      <pubDate>Sun, 27 Sep 2020 12:40:34 +0800</pubDate>
      
      <guid>/posts/2020-ithome-day19/</guid>
      <description>&lt;p&gt;我們前面花了一些時間了解 golang 的基本用法，以及資料一致性的重要性，並且在上一篇中討論到多 server 快取資料可能發生的狀況，其中在多 server 下如果能夠保持資料存取一致，並且依據流量更彈性的增減，便是 microservices 的最大特色。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Day18 Cache (Local Cache vs Redis)</title>
      <link>/posts/2020-ithome-day18/</link>
      <pubDate>Sat, 26 Sep 2020 14:39:08 +0800</pubDate>
      
      <guid>/posts/2020-ithome-day18/</guid>
      <description>&lt;p&gt;會有快取的需求是來自於使用者，對相同資料目標進行大量讀取，為了降低 RMDBS 連線數量與 RMDBS 的實體資源，所產生出來的架構策略。今天我們要來實作 cache，並且分別使用本地記憶體與共用noSQL兩種方式，進行比較其效果與其優劣。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Day17 Transactions (Redis)</title>
      <link>/posts/2020-ithome-day17/</link>
      <pubDate>Fri, 25 Sep 2020 12:34:17 +0800</pubDate>
      
      <guid>/posts/2020-ithome-day17/</guid>
      <description>&lt;p&gt;是的，我們今天要來討論一下 Redis 的 transaction。我們知道 Transaction 要嘛全執行要嘛全不執行，Redis 在 2.2 之後提供了 optimistic lock，讓我們得以進行 check-and-set 的可能，並且實作了幾個方法讓我們可以達成 transaction 的需求。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Day16 Transactions (MySQL)</title>
      <link>/posts/2020-ithome-day16/</link>
      <pubDate>Thu, 24 Sep 2020 18:01:01 +0800</pubDate>
      
      <guid>/posts/2020-ithome-day16/</guid>
      <description>&lt;p&gt;為了保持我們的資料能&lt;strong&gt;正確的寫入&lt;/strong&gt;與&lt;strong&gt;正確的不寫入&lt;/strong&gt;，今天我們要來了解一下 transactions 是怎麼運作的，以及如果沒有實作 transactions 會發生怎樣的悲劇，最後提供 gorm 實作 transactions 的範例程式碼給大家參考。&lt;/p&gt;
&lt;p&gt;Transactions 資料庫用來處理一連串 SQL queries的方式，用來防止服務需更新多筆資料或多個 table 時，任一筆資料更新失敗而產生的更新不完整狀態出現。被包在 transactions 中的的操作只要有一筆失敗便可以透過 rollback 來將其它已操作的部分復原。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Day15 Http Server &amp; Gorm</title>
      <link>/posts/2020-ithome-day15/</link>
      <pubDate>Wed, 23 Sep 2020 10:23:57 +0800</pubDate>
      
      <guid>/posts/2020-ithome-day15/</guid>
      <description>&lt;p&gt;依據進度我們要進入實做的部分了，昨天的 docker-compose，剛好幫我們建立了一組 slave-master MySQL database，今天將利用昨日的 DB 加上 Gin &amp;amp; Gorm packages，完成最簡易的 HTTP service。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Day14 Dockerfile &amp; Docker-Compose</title>
      <link>/posts/2020-ithome-day14/</link>
      <pubDate>Tue, 22 Sep 2020 10:38:17 +0800</pubDate>
      
      <guid>/posts/2020-ithome-day14/</guid>
      <description>&lt;p&gt;本日文章內容目標能讓我們了解，Dockerfile 撰寫的格式與啟動的效果，並且使用 docker-compose 啟動多個 containers，並建立兩個 containers 溝通的橋樑。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Day13 Docker</title>
      <link>/posts/2020-ithome-day13/</link>
      <pubDate>Mon, 21 Sep 2020 11:31:32 +0800</pubDate>
      
      <guid>/posts/2020-ithome-day13/</guid>
      <description>&lt;p&gt;為了讓我們可以快速獲得乾淨的測試資料庫，與後續 Go Distributed at Kubernetes，於此開始介紹一些關於容器的概念。希望能夠幫助一些對於環境苦手的朋友，可以在開發上有一個更快速乾淨的選擇。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Day12 Atomic</title>
      <link>/posts/2020-ithome-day12/</link>
      <pubDate>Sun, 20 Sep 2020 12:10:37 +0800</pubDate>
      
      <guid>/posts/2020-ithome-day12/</guid>
      <description>&lt;p&gt;關於 &lt;a href=&#34;https://golang.org/pkg/sync/atomic/&#34;&gt;sync/atomic&lt;/a&gt; 是於 &lt;a href=&#34;mailto:go@v1.14&#34;&gt;go@v1.14&lt;/a&gt; 才推出的新東西，筆者也是最近才知道有這個包可以使用。Atomic 目標在一些單純的操作上，完成最小原子性操作，使用上甚至比 mutex 更為簡便。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Day11 Mutex vs Channel</title>
      <link>/posts/2020-ithome-day11/</link>
      <pubDate>Sat, 19 Sep 2020 15:50:58 +0800</pubDate>
      
      <guid>/posts/2020-ithome-day11/</guid>
      <description>&lt;p&gt;昨天看過 race condiction 的情況後，我們了解了 mutex.Lock 與 channel，可以幫助我們同步 memory 狀態，避免發生奇怪的資料異常狀態。今天我們要延續昨天的技巧，並且用 benchmark 比較兩個在速度上的優劣。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Day10 Race Condition</title>
      <link>/posts/2020-ithome-day10/</link>
      <pubDate>Fri, 18 Sep 2020 13:39:05 +0800</pubDate>
      
      <guid>/posts/2020-ithome-day10/</guid>
      <description>&lt;p&gt;在昨天我們已經看過了 golang 併發的方式，今天我們要來學習如何控制我們的 goroutines。首先我們先來看一下 race condition(或稱data race) 的定義與範例，接著我們在使用 channel 與 mutex lock 來處理這樣的問題。&lt;/p&gt;
&lt;h2 id=&#34;race-condition&#34;&gt;Race Condition&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;A race condition or race hazard is the behavior of an electronics, software, or other system where the output is dependent on the sequence or timing of other uncontrollable events&lt;/p&gt;
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>Day9 Goroutine &amp; Concurrency</title>
      <link>/posts/2020-ithome-day9/</link>
      <pubDate>Thu, 17 Sep 2020 15:30:17 +0800</pubDate>
      
      <guid>/posts/2020-ithome-day9/</guid>
      <description>&lt;p&gt;今天不延用 BasicGo 的標題，並非 Concurrency 很困難，而是他在 golnag 中可以被輕易實踐，反而容易造成初學者的一些困擾與誤解，建議首次使用的朋友們慎重看待他。&lt;/p&gt;
&lt;h2 id=&#34;concurrency&#34;&gt;Concurrency&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;In computer science, concurrency is the ability of different parts or units of a program, algorithm, or problem to be executed out-of-order or in partial order, without affecting the final outcome&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;以下圖為例，將兩個任務個別拆分成較小的子任務，並且同時丟到 thread 中執行，由於是同時丟入 thread 中，所以順序上無法保證哪一個任務先被處理完成。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.monades.dev/concurrency-is-different-than-parallelism&#34;&gt;圖片來源&lt;/a&gt;
&lt;img src=&#34;https://user-images.githubusercontent.com/4419992/35572695-ee6275c8-05b3-11e8-8460-2c1ac7081574.jpg&#34; alt=&#34;Concurrency&#34;&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Day8 Basic Go (Initialize, Scope)</title>
      <link>/posts/2020-ithome-day8/</link>
      <pubDate>Wed, 16 Sep 2020 16:10:42 +0800</pubDate>
      
      <guid>/posts/2020-ithome-day8/</guid>
      <description>&lt;p&gt;今天我們要回來重新檢視一下 golang 的各種 Scope(作用域)，在開始 scope 的說明前還必須提到 golang 程式在 runtime 初始化的順序，確保我們對運行時每一個階段的掌握。&lt;/p&gt;
&lt;h2 id=&#34;initialization-order&#34;&gt;Initialization Order&lt;/h2&gt;
&lt;p&gt;當我們開始執行 golang 的程序時，首先會將 import packages 內部的常數變數與 init() 完成後，才開始當前 main package 下的常數變數與 init()，最後執行 main()。此外需注意的是每個 package 內的 init() 都只會被執行一次，如同其保留的命名為“初始化”時使用。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;import package&lt;/li&gt;
&lt;li&gt;const &amp;amp; var&lt;/li&gt;
&lt;li&gt;init()&lt;/li&gt;
&lt;li&gt;main()&lt;/li&gt;
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>Day7 Basic Go (Run, Syntax, Struct)</title>
      <link>/posts/2020-ithome-day7/</link>
      <pubDate>Tue, 15 Sep 2020 13:34:38 +0800</pubDate>
      
      <guid>/posts/2020-ithome-day7/</guid>
      <description>&lt;p&gt;在對環境有基本的了解後，我們終於要開始說基本語法拉～如果你是已經使用過 golang 的朋友，今天可以放心跳過這篇惹。今天我們會全速通過 golang所有基本該知道的語法，因為考量到後續篇幅的關係一些常見的型態介紹會被我省略。&lt;/p&gt;
&lt;h2 id=&#34;執行&#34;&gt;執行&lt;/h2&gt;
&lt;p&gt;讓我們以最簡單的範例檔開始吧！&lt;/p&gt;
&lt;p&gt;main.go&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;package&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;main&lt;/span&gt;

&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;fmt&amp;#34;&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;//主程式名稱固定為 main()
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;func&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;main&lt;/span&gt;() {
    &lt;span style=&#34;color:#a6e22e&#34;&gt;fmt&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;Println&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;hello world&amp;#34;&lt;/span&gt;)
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Day6 Basic Go (GO MODULES)</title>
      <link>/posts/2020-ithome-day6/</link>
      <pubDate>Mon, 14 Sep 2020 09:37:35 +0800</pubDate>
      
      <guid>/posts/2020-ithome-day6/</guid>
      <description>&lt;h2 id=&#34;go-modules&#34;&gt;Go Modules&lt;/h2&gt;
&lt;p&gt;為了解決 &lt;a href=&#34;mailto:go@1.11&#34;&gt;go@1.11&lt;/a&gt; 前，程式運行被限制於 GOPATH/src 下相依與編譯問題，套件相依管理 go modules 誕生了。先前提到 便是  Go Modules 是否啟用的環境設定值，可分為 on, off, auto 三種。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;on : 固定啟用 Go Modules ，在進行套件相依時會從 GOPATH/pkg/ 下查找&lt;/li&gt;
&lt;li&gt;off : 固定停用 Go Modules ，在進行套件相依時會從 GOPATH/src/ 下查找&lt;/li&gt;
&lt;li&gt;auto : Default setting 會依據你執行 go run or go build 等命令時的位置決定是否啟用 Go Modules ，若執行位置不在 GOPATH/src/ 下且目錄裡存在 go.mod 會啟用 Go Modules&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Day5 Basic Go (Install &amp; GOPATH)</title>
      <link>/posts/2020-ithome-day5/</link>
      <pubDate>Sun, 13 Sep 2020 12:59:41 +0800</pubDate>
      
      <guid>/posts/2020-ithome-day5/</guid>
      <description>&lt;h2 id=&#34;來個快速安裝吧&#34;&gt;來個快速安裝吧&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;官網下載安裝檔執行&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://golang.org/doc/install&#34;&gt;&lt;img src=&#34;https://i.imgur.com/54I2HSl.png&#34; alt=&#34;Download and install&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>Day4 Why Go</title>
      <link>/posts/2020-ithome-day4/</link>
      <pubDate>Sat, 12 Sep 2020 15:47:24 +0800</pubDate>
      
      <guid>/posts/2020-ithome-day4/</guid>
      <description>&lt;p&gt;先前幾天介紹 data consistency 的部分，是希望我們可以謹記資料對系統的重要性，從今天開始我們要進入用 golang 搭建 server 的實作部分，在我們可以實作前，不免俗的要介紹一下為什麼要用 golang 這個語言來進行。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Day3 CAP 定理</title>
      <link>/posts/2020-ithome-day3/</link>
      <pubDate>Fri, 11 Sep 2020 13:42:52 +0800</pubDate>
      
      <guid>/posts/2020-ithome-day3/</guid>
      <description>&lt;p&gt;Consistency(一致性), Availability (可用性), Partition Tolerance(分區容忍性) 組成 CAP 定理，在前一文中提到依據不同的狀況下我們必須面臨取捨的問題，藉由了解三者的定義與任取其二所產生出來的效果了解該如何取捨。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Day2 Data consistency</title>
      <link>/posts/2020-ithome-day2/</link>
      <pubDate>Thu, 10 Sep 2020 09:37:18 +0800</pubDate>
      
      <guid>/posts/2020-ithome-day2/</guid>
      <description>&lt;p&gt;會選擇在 distributed(分散式)之前先討論 consistency(一致性)，是由於如果我們的分散式系統所提供的服務無法保有一定程度的正確性的話，不論可以回應多大量或多快速的請求都是沒有意義的，而且可能會是一場巨大的災難。一般來說我們會討論到 data consistency，是基於複數存取實體因為時間差或實體間同步異常中斷，而產生的資料或狀態不一致，而單一 server 內因為多併發而產生的資料不一致屬於 data race 範疇，我們在後面一點的文章另外討論。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Day1 系列文結構介紹</title>
      <link>/posts/2020-ithome-day1/</link>
      <pubDate>Wed, 09 Sep 2020 08:48:12 +0800</pubDate>
      
      <guid>/posts/2020-ithome-day1/</guid>
      <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;HiHi~!時隔多年又回來參賽拉，本次希望已經涉入軟體系統開發的工程師可以從此系列文中得到一些想法，也希望還沒應用到分散式架構或對一致性不太了解的朋友，可以體會看看遇到什麼問題的時候會需要這樣的架構編排&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Private method 是否該進行單元測試？</title>
      <link>/posts/2019-11-26-test/</link>
      <pubDate>Tue, 26 Nov 2019 15:09:00 +0800</pubDate>
      
      <guid>/posts/2019-11-26-test/</guid>
      <description>&lt;p&gt;&lt;strong&gt;先講結論，不需要。&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>DevOps 2019</title>
      <link>/posts/2019-11-04-devops2019/</link>
      <pubDate>Mon, 04 Nov 2019 15:44:14 +0800</pubDate>
      
      <guid>/posts/2019-11-04-devops2019/</guid>
      <description>&lt;h2 id=&#34;day1-opens-space&#34;&gt;Day1 Opens Space&lt;/h2&gt;
&lt;p&gt;首次參加 Opens Space 這樣形式的交流方式，藉由成員各自發起議題自由且自發的進行討論，能收穫多少取決於參與的程度，不僅是聆聽者也是意見與問題的提供者，透過議題發起、討論、提問、回答來持續的找出可能性與盲點。&lt;/p&gt;
&lt;p&gt;其中參加了 “Waterfall 中的 Agile Scrum”、“到底是 DevOps 包含 Agile 還是 Agile 包含 DevOps”、“如何讓主管了解 DevOps 真正的理論好處” 這三個主題。三個主題的共通點是都有討論到如何去實踐 DevOps，DevOps 並非規範不是單一流程更非單一系統，更接近一個文化一個共同的價值交付的過程，但價值與文化的統一談何容易，故此狹義的 DevOps 可以讓我們從 CI/CD 做起，藉由統一持續驗證系統開發結果，減少人工手動的繁複程序加速交付流程，增加團隊信心，也同時直接增加商業利益。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Redis ELK</title>
      <link>/posts/2019-09-25-redis-elk/</link>
      <pubDate>Wed, 25 Sep 2019 14:12:14 +0800</pubDate>
      
      <guid>/posts/2019-09-25-redis-elk/</guid>
      <description>&lt;p&gt;結合 reids &amp;amp; ELK 搜集分散式 log。適合想統一異質平台或已微服務化的系統使用。&lt;/p&gt;
&lt;p&gt;僅需將目標 log RPUSH 至指定的 redis key，便可輕鬆地藉由 logstash 取出至 elasticserach 最後由 kibana 呈現。&lt;/p&gt;
&lt;h3 id=&#34;需求&#34;&gt;需求&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;docker-compose&lt;/li&gt;
&lt;li&gt;redis&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;repo&#34;&gt;Repo&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/WeiWeiWesley/ELK&#34;&gt;https://github.com/WeiWeiWesley/ELK&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kubernet Summit 2019</title>
      <link>/posts/2019-09-20-kubernet-summit-2019/</link>
      <pubDate>Fri, 20 Sep 2019 18:04:14 +0800</pubDate>
      
      <guid>/posts/2019-09-20-kubernet-summit-2019/</guid>
      <description>&lt;h3 id=&#34;簡易重點&#34;&gt;簡易重點&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;賣 K8s 的人不敢告訴你的事 - 葉秉哲（William）
&lt;ul&gt;
&lt;li&gt;導入前必須提出的問題：維運成本、拓展性、管理性&lt;/li&gt;
&lt;li&gt;供應商提供的數據是否符合現實需求&lt;/li&gt;
&lt;li&gt;現有架構是否已經完成解耦合微服務化，已適合搬遷&lt;/li&gt;
&lt;li&gt;配套CI/CD與分散式log收集監視是否完備&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>ModernWeb 2019</title>
      <link>/posts/2019-09-18-modernweb2049/</link>
      <pubDate>Wed, 18 Sep 2019 09:37:00 +0800</pubDate>
      
      <guid>/posts/2019-09-18-modernweb2049/</guid>
      <description>&lt;h2 id=&#34;簡易重點&#34;&gt;簡易重點&lt;/h2&gt;
&lt;h4 id=&#34;day1&#34;&gt;Day1&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Progressive Deployment &amp;amp; NoDeploy - 曾義峰 Ant
&lt;ul&gt;
&lt;li&gt;NoDeploy == No conscious Deploy(無察覺部署)&lt;/li&gt;
&lt;li&gt;ITIL -&amp;gt; DevOps-&amp;gt; SRE&lt;/li&gt;
&lt;li&gt;一切都在prodouction 完成(commit,測試,部署)&lt;/li&gt;
&lt;li&gt;適合工程師平均水準較高團隊&lt;/li&gt;
&lt;li&gt;漸進式部署，控制損壞範圍 (80% stable, 20% testing)&lt;/li&gt;
&lt;li&gt;chaos engineering&lt;/li&gt;
&lt;li&gt;所有程式皆為部署，並可控制開關，減少整合問題&lt;/li&gt;
&lt;li&gt;提交程式至主幹可能會影響其他功能&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>Websocket 壓測工具</title>
      <link>/posts/2019-06-30-webocketya-ce-gong-ju/</link>
      <pubDate>Sun, 30 Jun 2019 22:48:14 +0800</pubDate>
      
      <guid>/posts/2019-06-30-webocketya-ce-gong-ju/</guid>
      <description>&lt;p&gt;這是一個以 go語言編寫的 websocket壓測工具，提供併發連線、結果驗證、時間計算等功能。筆者目前使用的環境多為 Linux &amp;amp; MacOS，如果想在CLI簡單地對 websocket服務進行壓力測試的話，這邊提供一個簡單的工具給大家。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/WeiWeiWesley/WsTestTool&#34;&gt;Github Link&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>30Days ELK - Day30 30 days Review</title>
      <link>/posts/2019-01-14-elk/</link>
      <pubDate>Sat, 14 Jan 2017 14:28:00 +0800</pubDate>
      
      <guid>/posts/2019-01-14-elk/</guid>
      <description>&lt;h2 id=&#34;終於終於&#34;&gt;終於終於&lt;/h2&gt;
&lt;p&gt;終於終於走到這裡了，我先向一路看我拖搞到這的人說先抱歉與謝謝。寫這系列文章主要是剛好正在接觸 E.L.K 這套常見 log solution 時，朋友建議把學習的過程記錄下來，加深自己理解的內容也幫助別人可以有簡單的入門方式。當然我知道自己有很多地方的使用方式還不夠理想，還有很多需要改善的地方，還有很多可以發揮它強大效能的地方沒有補足，但我還是很開心的迎接這最後一天的到來 —— Done is better than perfect. 或許很多人對話此嗤之以鼻但我現在懂它的價值所在，如果真的要做到完美的話這系列文章是不會誕生的，他應該在Day23就結束了(笑)。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>30Days ELK - Day29 Optimization</title>
      <link>/posts/2018-01-13-elk/</link>
      <pubDate>Fri, 13 Jan 2017 20:34:56 +0800</pubDate>
      
      <guid>/posts/2018-01-13-elk/</guid>
      <description>&lt;p&gt;在使用 Elastic Stack 的過程中可藉由調整 logstash 資料過濾的方式、elasticsearch 資料儲存的方式來優化整體效能。個人在使用的過程中有遇到效能上的問題，一開始是資源使用不完全，cup的使用率一直無法接近滿載的情況而導致資料處理緩慢。後來想到一個簡單的方式在不改動環境設定值的情況下增加 logstash 的工作量 —— 直接增加 logstash container，這是唯有我們在 docker container 下才有辦法做到的解法，雖然多虛擬機會犧牲部分資源，但能夠用這種方式使得資源被完全使用對當下的我來說是最重要的，如果你跟我一樣只是想多使用一點資源的話這或許是一個簡單不錯的方式。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;But if you want to do it by the right way. 你需要參考&lt;a href=&#34;https://www.elastic.co/guide/en/logstash/current/logstash-settings-file.html&#34;&gt;官方文件&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>30Days ELK - Day28 Kibana Extended Metric Plugin</title>
      <link>/posts/2017-01-12-elk/</link>
      <pubDate>Thu, 12 Jan 2017 23:42:06 +0800</pubDate>
      
      <guid>/posts/2017-01-12-elk/</guid>
      <description>&lt;p&gt;終於快要結束了，其實寫到這裡已經超過我於本預計想分享的部分了，所以很多東西真的是現學現賣，這次也是分享一個小插件的安裝與使用方式，還希望大家不嫌棄囉。&lt;/p&gt;
&lt;h2 id=&#34;kibana-extended-metric-plugin&#34;&gt;Kibana Extended Metric Plugin&lt;/h2&gt;
&lt;p&gt;這個插件十分簡易，這邊直接提供測試資料與設定檔供大家，下載試玩。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>30Days ELK - Day27 地震熱區資料視覺化測試範例</title>
      <link>/posts/2017-01-11-elk/</link>
      <pubDate>Wed, 11 Jan 2017 23:42:06 +0800</pubDate>
      
      <guid>/posts/2017-01-11-elk/</guid>
      <description>&lt;p&gt;這篇其實使用的技巧與上篇差異不大，主要是提供一個資料，讓大家可以快速做出 Dashboard 並調整成符合自己的需求。當然你也可以參照 logstash.conf 調整一下資料過濾的方式，之前一直沒有提到的 grok 小技巧是其實你可以利用 (?:ValueA | ValueB) 的方式給予 field 預設值。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>30Days ELK - Day26 Apache log 測試範例懶人包</title>
      <link>/posts/2017-01-10-elk/</link>
      <pubDate>Tue, 10 Jan 2017 22:19:06 +0800</pubDate>
      
      <guid>/posts/2017-01-10-elk/</guid>
      <description>&lt;p&gt;提醒沒看過前面的朋友想直接拿首先基本安裝還是要有，可參考 [Day2 - 來個快速安裝吧](- 來個快速安裝吧) 獲得基本環境部署，開啟 &lt;a href=&#34;http://127.0.0.1:5601/app/kibana&#34;&gt;Kibana local&lt;/a&gt; 確定服務能正確啟動。&lt;/p&gt;
&lt;p&gt;來囉快速咻咻咻完成它&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>30Days ELK - Day25 Kibana X-Pack Graph</title>
      <link>/posts/2017-01-09-elk/</link>
      <pubDate>Mon, 09 Jan 2017 23:11:23 +0800</pubDate>
      
      <guid>/posts/2017-01-09-elk/</guid>
      <description>&lt;p&gt;再開始講 Graph 之前我要跟大家提醒一下加裝 X-Pack 後你可能會遇到無法使用 tcp 當 input 的情況，然後一直跑去檢查 logstash container 的設定卻又苦無結果，其實這不是 logstash 壞掉哦!是 elasticsearch 上的 x-pack 因增加了權限管理而把 logstash 送過來的請求擋掉了，我們僅需簡單地在送至 elasticsearch 時帶上帳號密碼即可。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>30Days ELK - Day24 Kinban Plugin X-Pack Monitoring</title>
      <link>/posts/2017-01-08-elk/</link>
      <pubDate>Sun, 08 Jan 2017 22:05:35 +0800</pubDate>
      
      <guid>/posts/2017-01-08-elk/</guid>
      <description>&lt;p&gt;不好意思昨天出了意料之外的錯誤 (註：其實這篇應該昨天就要打出來的)，其實我也是一邊查資料一邊安裝 x-pack 這個 kibana plugin &lt;img src=&#34;/ithome/emoticon16.gif&#34; alt=&#34;emoticon16.gif&#34;&gt;&lt;/p&gt;
&lt;p&gt;所以先前雖然裝好了 x-pack 也成功登入我們的 kibana web 介面，但最重要的就是這個 &amp;ldquo;but&amp;rdquo;，他完全沒有達到我本來想跟大家分享的功能，觀察 elasticsearch cluster nodes。其實僅是我在安裝的時候竟然！竟然！只在 elasticsearch 一個節點上未安裝 x-pack&lt;/p&gt;
&lt;p&gt;這下真是尷尬今天會再重新分享一下更簡單的安裝方式，以及 X-Pack 提供的主要功能。想用昨天那種直接進入容器的方式安裝也可以，只是要記得所有的 elasticsearch nodes 都要裝哦～要是你覺得這樣太麻煩了這邊提供一個比較優雅的方式，也是一樣直接在啟動容器上改變設置：&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>30Days ELK - Day23 Kibana Plugin X-Pack Install</title>
      <link>/posts/2017-01-07-elk/</link>
      <pubDate>Sat, 07 Jan 2017 23:37:38 +0800</pubDate>
      
      <guid>/posts/2017-01-07-elk/</guid>
      <description>&lt;p&gt;今天要介紹一個超好用的 kibana plugin，X-Pack。你一定要安裝的好用插件讓我們先裝在說。&lt;/p&gt;
&lt;p&gt;就讓我們照著&lt;a href=&#34;https://www.elastic.co/downloads/x-pack&#34;&gt;官網&lt;/a&gt;的六步驟來安裝吧(只是我們是裝在 docker 上)&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>30Days ELK - Day22 Multi logstash machines used for monitoring.</title>
      <link>/posts/2017-01-06-elk/</link>
      <pubDate>Fri, 06 Jan 2017 17:30:01 +0800</pubDate>
      
      <guid>/posts/2017-01-06-elk/</guid>
      <description>&lt;p&gt;今天介紹的是一個利用虛擬機使用 logstash 的技巧，當我們有一台較高效能實體機器且有多個不同的資料來源時，我們可能會把 logstash.conf 用 file 檔名或 tcp port 來進行區別如：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-toml&#34; data-lang=&#34;toml&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;input&lt;/span&gt; {
        &lt;span style=&#34;color:#a6e22e&#34;&gt;tcp&lt;/span&gt; {
                &lt;span style=&#34;color:#a6e22e&#34;&gt;port&lt;/span&gt; =&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5000&lt;/span&gt;
                &lt;span style=&#34;color:#a6e22e&#34;&gt;type&lt;/span&gt; =&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;access&amp;#34;&lt;/span&gt;
        }

        &lt;span style=&#34;color:#a6e22e&#34;&gt;tcp&lt;/span&gt; {
                &lt;span style=&#34;color:#a6e22e&#34;&gt;port&lt;/span&gt; =&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5001&lt;/span&gt;
                &lt;span style=&#34;color:#a6e22e&#34;&gt;type&lt;/span&gt; =&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;error&amp;#34;&lt;/span&gt;
        }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>30Days ELK - Day21 Elasticsearch Cluster</title>
      <link>/posts/2017-01-05-elk/</link>
      <pubDate>Thu, 05 Jan 2017 23:49:30 +0800</pubDate>
      
      <guid>/posts/2017-01-05-elk/</guid>
      <description>&lt;p&gt;我們進行到今天已經可以將 E.L.K 運行並實現資料分析、資料儲存、資料探索與視覺化，現在我們需要做的是提升它的可靠性與面對效能瓶頸時拓展自身的能力。這時候 elasticsearch cluster 就派上用場拉，至少要讓你的資料能夠有個備份，假設 docker container 毀損甚至機器毀損時能不受引響。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>30Days ELK - Day20 Dockerfile &amp; docker-compose</title>
      <link>/posts/2017-01-04-elk/</link>
      <pubDate>Wed, 04 Jan 2017 20:50:41 +0800</pubDate>
      
      <guid>/posts/2017-01-04-elk/</guid>
      <description>&lt;p&gt;有了 docker 基本的概念後我們回頭看一下 docker 的設定檔 Dockerfile 與 docker-compose.yml，瞭解一下 logstash, elasticsearch, kibana 的虛擬機是怎麼被設定與啟用的。有了這些知識後能幫助我們解決一些 E.L.K 使用上或配置上的問題。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>30Days ELK - Day19 Docker</title>
      <link>/posts/2017-01-03-elk/</link>
      <pubDate>Tue, 03 Jan 2017 19:47:23 +0800</pubDate>
      
      <guid>/posts/2017-01-03-elk/</guid>
      <description>&lt;p&gt;你以為看錯標題了嗎？沒有哦～就是 docker 沒錯，為了延續後面我要講一些插件與優化配置的方式，這邊必須簡單提一下 docker 讓後面在能夠比較簡單的銜接上，真的是簡單講一下因為接觸 docker 時間不夠長，讓我們快速走過吧。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>30Days ELK - Day18 Dashboard</title>
      <link>/posts/2017-01-02-elk/</link>
      <pubDate>Mon, 02 Jan 2017 20:12:59 +0800</pubDate>
      
      <guid>/posts/2017-01-02-elk/</guid>
      <description>&lt;p&gt;先前我們在 Visualize 繪製了許多圖表，這些圖表可能個別代表不同資訊內容或比較，當然我們有可能需要整合這些資訊到同一個頁面裡，這時侯 Dashboard 就登場拉～多個願望一次滿足。當然前提是你要在 Visualize 繪製儲存所需的圖表然後到 Dashboard 就可以直接加入囉。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>30Days ELK - Day17 Bar chart. Tag Cloud. Tile map</title>
      <link>/posts/2017-01-01-elk/</link>
      <pubDate>Sun, 01 Jan 2017 23:34:12 +0800</pubDate>
      
      <guid>/posts/2017-01-01-elk/</guid>
      <description>&lt;p&gt;我們今天來把 kiban visualize 的部分收個尾，首先介紹的是最常用到的 bar chart，設置的方式與 line chart, area chart 相同都是現設定好 x軸、y軸，再加入想要聚合的屬性。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>30Days ELK - Day16 Visualize data with pie chart. Count by metric</title>
      <link>/posts/2016-12-31-elk/</link>
      <pubDate>Sat, 31 Dec 2016 19:00:27 +0800</pubDate>
      
      <guid>/posts/2016-12-31-elk/</guid>
      <description>&lt;p&gt;另個常見的視覺化方式“圓餅圖 pie chart”，圓餅圖可以很有效地對資料進行展示。特別是在想要表示某個大扇型區在整體中所占比例，這一方法十分有效。設置流程與其他圖表大同小異，讓我們快速的一步驟一步驟完成他吧。若用範例資料進行練習，資料切割配置可參考Day15於此不重複說明囉。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>30Days ELK - Day15 DataTable</title>
      <link>/posts/2016-12-30-elk/</link>
      <pubDate>Fri, 30 Dec 2016 18:23:53 +0800</pubDate>
      
      <guid>/posts/2016-12-30-elk/</guid>
      <description>&lt;p&gt;好了我來還債了，我們繼續來看看 kibana visualize 還有什麼可以提供的。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>30Days ELK - Day14 Visualize data with area chart. Markdown your document.</title>
      <link>/posts/2016-12-29-elk/</link>
      <pubDate>Thu, 29 Dec 2016 22:42:13 +0800</pubDate>
      
      <guid>/posts/2016-12-29-elk/</guid>
      <description>&lt;p&gt;Area chart 基本繪製與 line chart 無異&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>30Days ELK - Day13 Visualize data with line chart &amp; bubble chart</title>
      <link>/posts/2016-12-28-elk/</link>
      <pubDate>Wed, 28 Dec 2016 21:29:57 +0800</pubDate>
      
      <guid>/posts/2016-12-28-elk/</guid>
      <description>&lt;p&gt;今天要來畫畫圖兒，如果想完全照著做的話請使用下方 logstash.conf 檔配置，資料來源一樣使用&lt;a href=&#34;http://www.monitorware.com/en/logsamples/apache.php&#34;&gt;apache sample logs&lt;/a&gt;。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>30Days ELK - Day12 Reformate timestamp</title>
      <link>/posts/2016-12-27-elk/</link>
      <pubDate>Tue, 27 Dec 2016 21:50:44 +0800</pubDate>
      
      <guid>/posts/2016-12-27-elk/</guid>
      <description>&lt;p&gt;延續先前 Discover 的部分，如何讓我們的紀錄時間 match 上 log 的紀錄時間呢?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>30Days ELK - Day11 Discover data freely by any shape anytime</title>
      <link>/posts/2016-12-26-elk/</link>
      <pubDate>Mon, 26 Dec 2016 13:50:19 +0800</pubDate>
      
      <guid>/posts/2016-12-26-elk/</guid>
      <description>&lt;p&gt;首先我們先抓一份測試用的 apache log 協助我們有相同的資料可以做解說。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>30Days ELK - Day10 Kibana</title>
      <link>/posts/2016-12-25-elk/</link>
      <pubDate>Sun, 25 Dec 2016 21:09:52 +0800</pubDate>
      
      <guid>/posts/2016-12-25-elk/</guid>
      <description>&lt;p&gt;Ola~讓我們開心的使用圖形化介面吧。
終於講到可以讓我們把資料以 html 顯示的方式囉，kibana 也就是 E.L.K 裡的 Ｋ將由 logstash 過濾完並儲存到 elasticsearch 的資料透過設定 index 進行索引。今天就先讓我們來檢視一下介面上有哪些區塊及其所屬的功能。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>30Days ELK - Day9 Elasticsearch 狀態檢視</title>
      <link>/posts/2016-12-24-elk/</link>
      <pubDate>Sat, 24 Dec 2016 21:43:22 +0800</pubDate>
      
      <guid>/posts/2016-12-24-elk/</guid>
      <description>&lt;p&gt;今天簡單介紹一下幾個觀察 elasticsearch 的指令與方法，讓我從個人最常用的index目錄說起。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>30Days ELK - Day8 Elasticsearch CRUD</title>
      <link>/posts/2016-12-23-elk/</link>
      <pubDate>Fri, 23 Dec 2016 23:10:12 +0800</pubDate>
      
      <guid>/posts/2016-12-23-elk/</guid>
      <description>&lt;p&gt;之前提過 elasticsearh 是個擁有全 RESTful API 操作的分散式資料庫，於且向大家介紹一下其基本操作的方法。雖然不見得在使用 E.L.K 會用到，畢竟解析由 logstash 完成了，一般存取也可以由 kibana 完成，但如果想針對單筆紀錄作微調或測試你還是會用到以 curl CRUD 操作的。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>30Days ELK - Day7 Elasticsearch</title>
      <link>/posts/2016-12-22-elk/</link>
      <pubDate>Thu, 22 Dec 2016 19:50:02 +0800</pubDate>
      
      <guid>/posts/2016-12-22-elk/</guid>
      <description>&lt;p&gt;Elasticsearch 是我們之後再 kibana 之所以可以快速的呼叫與搜尋的關鍵，我們來簡單暸解一下 elasticsearch 的特性與他在 E.L.K 中扮演的角色。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>30Days ELK - Day6 便利的 logstsh plugin (filter - 2)</title>
      <link>/posts/2016-12-21-elk/</link>
      <pubDate>Wed, 21 Dec 2016 14:12:52 +0800</pubDate>
      
      <guid>/posts/2016-12-21-elk/</guid>
      <description>&lt;p&gt;今天繼續來看一下有什麼實用的 filter plugins 可以協助我們把資訊從原始資料切割出來。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>30Days ELK - Day5  便利的 logstash plugin (filter)</title>
      <link>/posts/2016-12-20-elk/</link>
      <pubDate>Tue, 20 Dec 2016 20:21:00 +0800</pubDate>
      
      <guid>/posts/2016-12-20-elk/</guid>
      <description>&lt;p&gt;Filter plugins 可以說是整個 logstash 最核心的部分，多數你想要過濾的資料內容都可以仰賴其進行。而 filter plugins 的選擇與配置多數相關於一開始輸入的資料類型，舉例來說你的資料可能含有 geographical location 那你的 filter plugins 就可以加上 geoip ，來幫助你切割出經緯度、地區、國家、時區等資訊。以下簡單介紹一下幾個實用的 filter plugins 使用方式。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>30Days ELK - Day4  便利的 logstash plugin (input)</title>
      <link>/posts/2016-12-19-elk/</link>
      <pubDate>Mon, 19 Dec 2016 17:33:23 +0800</pubDate>
      
      <guid>/posts/2016-12-19-elk/</guid>
      <description>&lt;p&gt;我們在昨天的內容分享了基本的 logstash 使用方式，今天要介紹的則是 logstash 的 input plugins 。其實 logstash 的運作除了基於其 input, filter, ouput 的架構外，在這三層架構中使用的 plugins 才是讓整個 logstash 具有資料切割與過濾能力的核心關鍵，input plugins 提供了我們獲取各式不同資料來源的方式，以下分別介紹幾個常用的 input plugin。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>30Days ELK - Day3  logstash 輸入配置</title>
      <link>/posts/2016-12-18-elk/</link>
      <pubDate>Sun, 18 Dec 2016 19:52:07 +0800</pubDate>
      
      <guid>/posts/2016-12-18-elk/</guid>
      <description>&lt;p&gt;首先 logstash 是 E.L.K 最先觸碰到你想要管理 log 部分，你可以把他想成一個介接層也是首次接觸到 log 或資料的地方，在這裡你可以選擇你的輸入來源像是直接讀 log 檔，抑或是當你想直接接受多台機器的 log 時你可以使用 tcp 作為接口。其次當多個來源的資料想分別處理成不同資訊時，在 logstash 提供的 input 可以協助我們預先做出簡單的類別判斷，以利後續 filter 分別使用不同的規則進行切割，最後於 output 選擇要輸出的方式與位置。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>30Days ELK - Day2 來個快速安裝吧</title>
      <link>/posts/2016-12-17-elk/</link>
      <pubDate>Sat, 17 Dec 2016 14:52:07 +0800</pubDate>
      
      <guid>/posts/2016-12-17-elk/</guid>
      <description>&lt;h2 id=&#34;安裝部屬-&#34;&gt;安裝部屬 :&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;安裝 docker
&lt;a href=&#34;https://joshhu.gitbooks.io/docker_theory_install/content/DockerBible/ubuntuvm.html&#34;&gt;https://joshhu.gitbooks.io/docker_theory_install/content/DockerBible/ubuntuvm.html&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>30Days ELK - Day1 Why E.L.K</title>
      <link>/posts/2016-12-16-elk/</link>
      <pubDate>Fri, 16 Dec 2016 14:52:07 +0800</pubDate>
      
      <guid>/posts/2016-12-16-elk/</guid>
      <description>&lt;p&gt;初次接觸 E.L.K 希望藉由記錄下學習過程，幫助自己與初次接觸 E.L.K的新手了解其安裝的過程、使用的方法與可能會遇到的困難。首先我們先了解一下 E.L.K 是什麼?&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
